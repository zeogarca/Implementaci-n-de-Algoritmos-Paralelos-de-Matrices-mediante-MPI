  GNU nano 8.1                                                                                                                                                                        matrix_mpi_openmp.c                                                                                                                                                                                 
#include <stdio.h>
#include <stdlib.h>
#include <mpi.h>
#include <omp.h>
#include <time.h>

void fill_matrix(float *matrix, int N) {
    for (int i = 0; i < N * N; i++)
        matrix[i] = (float)(rand() % 10);
}

void print_matrix(const char *name, float *matrix, int N) {
    printf("%s:\n", name);
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++)
            printf("%6.2f ", matrix[i * N + j]);
        printf("\n");
    }
}

int main(int argc, char *argv[]) {
    int rank, size, N;

    if (argc != 2) {
        fprintf(stderr, "Usage: %s <matrix_size>\n", argv[0]);
        exit(EXIT_FAILURE);
    }

    N = atoi(argv[1]);
    if (N <= 0) {
        fprintf(stderr, "Matrix size must be positive\n");
        exit(EXIT_FAILURE);
    }

    MPI_Init(&argc, &argv);
    double start_time, end_time;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    srand(time(NULL) + rank);

    int rows_per_proc = N / size;
    int remainder = N % size;

    int *sendcounts = malloc(size * sizeof(int));
    int *displs = malloc(size * sizeof(int));
    int *recvcounts = malloc(size * sizeof(int));
    int *recvdispls = malloc(size * sizeof(int));

    int offset = 0;
    for (int i = 0; i < size; i++) {
        int rows = rows_per_proc + (i < remainder ? 1 : 0);
        sendcounts[i] = rows * N;
        displs[i] = offset;
        recvcounts[i] = rows * N;
        recvdispls[i] = offset;
        offset += rows * N;
    }

    float *A = NULL, *B = NULL, *C = NULL;
    if (rank == 0) {
        A = malloc(N * N * sizeof(float));
        B = malloc(N * N * sizeof(float));
        C = malloc(N * N * sizeof(float));
        fill_matrix(A, N);
        fill_matrix(B, N);
    }

    float *local_A = malloc(sendcounts[rank] * sizeof(float));
    float *local_C = malloc(sendcounts[rank] * sizeof(float));

    if (!local_A || !local_C || (rank == 0 && (!A || !B || !C))) {
        fprintf(stderr, "Memory allocation failed on rank %d\n", rank);
        MPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE);
    }

    if (rank == 0)
        start_time = MPI_Wtime();

    MPI_Scatterv(A, sendcounts, displs, MPI_FLOAT, local_A, sendcounts[rank], MPI_FLOAT, 0, MPI_COMM_WORLD);

    if (rank != 0)
        B = malloc(N * N * sizeof(float));

    MPI_Bcast(B, N * N, MPI_FLOAT, 0, MPI_COMM_WORLD);

    int local_rows = sendcounts[rank] / N;

    #pragma omp parallel for collapse(2)
    for (int i = 0; i < local_rows; i++) {
        for (int j = 0; j < N; j++) {
            float sum = 0.0;
            for (int k = 0; k < N; k++) {}

